{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from models.fourier_nn import FourierNet\n",
    "from problems.dist_online_dense_problem import DistOnlineDensityProblem\n",
    "from optimizers.dinno import DiNNO\n",
    "from optimizers.dsgt import DSGT\n",
    "from optimizers.dsgd import DSGD\n",
    "from optimizers.sonata import SONATA \n",
    "from utils import graph_generation\n",
    "from floorplans.lidar.lidar import (\n",
    "    Lidar2D,\n",
    "    OnlineTrajectoryLidarDataset,\n",
    "    RandomPoseLidarDataset,\n",
    ")\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "def train_solo(model, loss, train_set, val_set, device, conf):\n",
    "    \"\"\"Performs normal training without any communication\n",
    "\n",
    "    Args:\n",
    "        model (torch model): the model to train\n",
    "        loss (torch loss func): the loss function to train with.\n",
    "        trainset (torch dataset): training dataset\n",
    "        valset (torch dataset): validation dataset\n",
    "        device (torch device): device to compute on (cpu or gpu)\n",
    "        conf (dict): configuration dictionary (see yaml descriptions)\n",
    "\n",
    "    Returns:\n",
    "        dict: validation loss (float) after final epoch, and\n",
    "            the trained models density outputs (tensor)\n",
    "            evaluated on a mesh grid.\n",
    "    \"\"\"\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_set, conf[\"train_batch_size\"], shuffle=True\n",
    "    )\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_set, conf[\"val_batch_size\"], shuffle=True\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    if conf[\"optimizer\"] == \"adam\":\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=conf[\"lr\"])\n",
    "    elif conf[\"optimizer\"] == \"sgd\":\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=conf[\"lr\"])\n",
    "    elif conf[\"optimizer\"] == \"adamw\":\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=conf[\"lr\"])\n",
    "    else:\n",
    "        raise NameError(\"Unknown individual optimizer.\")\n",
    "\n",
    "    for _ in range(conf[\"epochs\"]):\n",
    "        for batch in trainloader:\n",
    "            opt.zero_grad()\n",
    "            pd = model.forward(batch[0].to(device))\n",
    "            l = loss(pd.squeeze(), batch[1].to(device))\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vloss = 0.0\n",
    "        for batch in valloader:\n",
    "            pd = model.forward(batch[0].to(device))\n",
    "            vloss += loss(pd.squeeze(), batch[1].to(device)).data.detach()\n",
    "\n",
    "        X, Y = np.meshgrid(val_set.lidar.xs, val_set.lidar.ys)\n",
    "        xlocs = X[::8, ::8].reshape(-1, 1)\n",
    "        ylocs = Y[::8, ::8].reshape(-1, 1)\n",
    "        mesh_poses = np.hstack((xlocs, ylocs))\n",
    "        mesh_inputs = torch.Tensor(mesh_poses)\n",
    "        mesh_inputs = mesh_inputs.to(device)\n",
    "\n",
    "        mesh_dense = model.forward(mesh_inputs)\n",
    "\n",
    "    return {\n",
    "        \"validation_loss\": vloss,\n",
    "        \"mesh_grid_density\": mesh_dense,\n",
    "        \"mesh_grid\": mesh_inputs,\n",
    "    }\n",
    "\n",
    "\n",
    "def experiment(yaml_pth):\n",
    "    # load the config yaml\n",
    "    with open(yaml_pth) as f:\n",
    "        conf_dict = yaml.safe_load(f)\n",
    "\n",
    "    # Seperate configuration groups\n",
    "    exp_conf = conf_dict[\"experiment\"]\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    torch.manual_seed(exp_conf[\"seed\"])\n",
    "\n",
    "    # Create the output directory\n",
    "    output_metadir = exp_conf[\"output_metadir\"]\n",
    "    if not os.path.exists(output_metadir):\n",
    "        os.mkdir(output_metadir)\n",
    "\n",
    "    time_now = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    output_dir = os.path.join(\n",
    "        output_metadir, time_now + \"_\" + exp_conf[\"name\"]\n",
    "    )\n",
    "\n",
    "    if exp_conf[\"writeout\"]:\n",
    "        os.mkdir(output_dir)\n",
    "        # Save a copy of the conf to the output directory\n",
    "        copyfile(yaml_pth, os.path.join(output_dir, time_now + \".yaml\"))\n",
    "    exp_conf[\"output_dir\"] = output_dir  # probably bad practice\n",
    "\n",
    "    # Load the datasets, and lidar object\n",
    "    data_conf = exp_conf[\"data\"]\n",
    "    print(\"Loading the data ...\")\n",
    "    img_path = os.path.join(data_conf[\"data_dir\"], \"floor_img.png\")\n",
    "\n",
    "    lidar = Lidar2D(\n",
    "        img_path,\n",
    "        data_conf[\"num_beams\"],\n",
    "        data_conf[\"beam_length\"],\n",
    "        data_conf[\"beam_samps\"],\n",
    "        data_conf[\"samp_distribution_factor\"],\n",
    "        data_conf[\"collision_samps\"],\n",
    "        data_conf[\"fine_samps\"],\n",
    "        border_width=data_conf[\"border_width\"],\n",
    "    )\n",
    "\n",
    "    data_dir = data_conf[\"data_dir\"]\n",
    "    waypoint_pths = glob.glob(\n",
    "        os.path.join(data_dir, data_conf[\"waypoint_subdir\"], \"*.npy\")\n",
    "    )\n",
    "    N = len(waypoint_pths)\n",
    "\n",
    "    # Check that N is consistent with the number of\n",
    "    # trajectories that are avaliable.\n",
    "    if N > len(waypoint_pths):\n",
    "        error_str = \"Requested more nodes than there are waypoint files.\"\n",
    "        error_str += \"Requested {} nodes, and found {} waypoint files.\".format(\n",
    "            N, len(waypoint_pths)\n",
    "        )\n",
    "        raise NameError(error_str)\n",
    "\n",
    "    train_subsets = []\n",
    "    for i in range(N):\n",
    "        waypoints = np.load(waypoint_pths[i])\n",
    "        node_set = OnlineTrajectoryLidarDataset(\n",
    "            lidar,\n",
    "            waypoints,\n",
    "            data_conf[\"spline_res\"],\n",
    "            data_conf[\"num_scans_in_window\"],\n",
    "            round_density=data_conf[\"round_density\"],\n",
    "        )\n",
    "        train_subsets.append(node_set)\n",
    "\n",
    "    # Print the dataset sizes\n",
    "    for i in range(N):\n",
    "        print()\n",
    "        print(\"Node \", i, \"train set size: \", len(train_subsets[i]))\n",
    "        print(\n",
    "            \"Node\",\n",
    "            i,\n",
    "            \"hd ratio: {:.4f}\".format(\n",
    "                (\n",
    "                    torch.sum(train_subsets[i].scans[:, 2] == 1.0)\n",
    "                    / train_subsets[i].scans.shape[0]\n",
    "                ).data.item()\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # Generate the validation set\n",
    "    val_set = RandomPoseLidarDataset(\n",
    "        lidar,\n",
    "        data_conf[\"num_validation_scans\"],\n",
    "        round_density=data_conf[\"round_density\"],\n",
    "    )\n",
    "\n",
    "    # Generate base model\n",
    "    model_conf = exp_conf[\"model\"]\n",
    "    base_model = FourierNet(model_conf[\"shape\"], scale=model_conf[\"scale\"])\n",
    "\n",
    "    # Define base loss\n",
    "    if exp_conf[\"loss\"] == \"BCE\":\n",
    "        base_loss = torch.nn.BCELoss()\n",
    "    elif exp_conf[\"loss\"] == \"MSE\":\n",
    "        base_loss = torch.nn.MSELoss()\n",
    "    elif exp_conf[\"loss\"] == \"L1\":\n",
    "        base_loss = torch.nn.L1Loss()\n",
    "    else:\n",
    "        raise NameError(\"Unknown loss function.\")\n",
    "\n",
    "    # Check for gpu and assign device\n",
    "    if torch.cuda.is_available() and exp_conf[\"use_cuda\"]:\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Device is set to GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Device is set to CPU\")\n",
    "\n",
    "    solo_confs = exp_conf[\"individual_training\"]\n",
    "    solo_results = {}\n",
    "    if solo_confs[\"train_solo\"]:\n",
    "        print(\"Performing individual training ...\")\n",
    "        for i in range(N):\n",
    "            solo_results[i] = train_solo(\n",
    "                copy.deepcopy(base_model),\n",
    "                base_loss,\n",
    "                train_subsets[i],\n",
    "                val_set,\n",
    "                device,\n",
    "                solo_confs,\n",
    "            )\n",
    "\n",
    "            if solo_confs[\"verbose\"]:\n",
    "                print(\n",
    "                    \"Node {} - Validation loss = {:.4f}\".format(\n",
    "                        i, solo_results[i][\"validation_loss\"]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        if exp_conf[\"writeout\"]:\n",
    "            torch.save(\n",
    "                solo_results, os.path.join(output_dir, \"solo_results.pt\")\n",
    "            )\n",
    "    # Run each problem\n",
    "    prob_confs = conf_dict[\"problem_configs\"]\n",
    "\n",
    "    for prob_key in prob_confs:\n",
    "        prob_conf = prob_confs[prob_key]\n",
    "        opt_conf = prob_conf[\"optimizer_config\"]\n",
    "\n",
    "        prob = DistOnlineDensityProblem(\n",
    "            base_model,\n",
    "            base_loss,\n",
    "            train_subsets,\n",
    "            val_set,\n",
    "            device,\n",
    "            prob_conf,\n",
    "        )\n",
    "\n",
    "        if opt_conf[\"alg_name\"] == \"dinno\":\n",
    "            dopt = DiNNO(prob, device, opt_conf)\n",
    "        elif opt_conf[\"alg_name\"] == \"dsgt\":\n",
    "            dopt = DSGT(prob, device, opt_conf)\n",
    "        elif opt_conf[\"alg_name\"] == \"dsgd\":\n",
    "            dopt = DSGD(prob, device, opt_conf)\n",
    "        elif opt_conf[\"alg_name\"] == \"sonata\":\n",
    "            dopt = SONATA(prob, device, opt_conf)\n",
    "        else:\n",
    "            raise NameError(\"Unknown distributed opt algorithm.\")\n",
    "\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\"-------------------------------------------------------\")\n",
    "        print(\"Running problem: \" + prob_conf[\"problem_name\"])\n",
    "        if opt_conf[\"profile\"]:\n",
    "            with torch.profiler.profile(\n",
    "                schedule=torch.profiler.schedule(\n",
    "                    wait=1, warmup=1, active=3, repeat=3\n",
    "                ),\n",
    "                on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "                    os.path.join(\n",
    "                        output_dir, prob_conf[\"problem_name\"] + \"opt_profile\"\n",
    "                    )\n",
    "                ),\n",
    "                record_shapes=True,\n",
    "                with_stack=True,\n",
    "            ) as prof:\n",
    "                dopt.train(profiler=prof)\n",
    "        else:\n",
    "            dopt.train()\n",
    "\n",
    "        if exp_conf[\"writeout\"]:\n",
    "            prob.save_metrics(output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    yaml_pth = sys.argv[1]\n",
    "\n",
    "    # Load the configuration file, and run the experiment\n",
    "    if os.path.exists(yaml_pth):\n",
    "        experiment(yaml_pth)\n",
    "    else:\n",
    "        raise NameError(\"YAML configuration file does not exist, exiting!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
