experiment:
  name: "dist_cifar_PAPER"
  data_dir: "../data/"
  output_metadir: "../results/"
  use_cuda: true
  writeout: true
  data_split_type: "random"
  loss: "NLL" # Cross Entropy
  graph:
    num_nodes: 10
    type: "cycle"
    p: 0.3
    gen_attempts: 100
  model:
    num_filters: 3
    kernel_size: 5
    linear_width: 64
  individual_training:
    train_solo: False
    optimizer: "adam"
    lr: 0.005
    epochs: 6
    train_batch_size: 100
    val_batch_size: 100
    verbose: true
problem_configs:
  problem1:
    problem_name: "sonata"
    train_batch_size: 64
    val_batch_size: 128
    verbose_evals: true
    metrics:
      - "forward_pass_count"
      - "validation_loss"
      - "consensus_error"
      - "top1_accuracy"
      - "current_epoch"
    metrics_config:
      evaluate_frequency: 20
    optimizer_config:
      alg_name: "sonata"
      alpha: 1
      tau: 0.001
      use_prox: False
      outer_iterations: 4000
      primal_iterations: 3
      init_grads: True
      primal_optimizer: "adam"
      persistant_primal_opt: false
      primal_lr_start: 0.01
      primal_lr_finish: 0.0001
      lr_decay_type: "log"
      profile: false
  #   problem1:
  #     problem_name: "sonata"
  #     train_batch_size: 64
  #     val_batch_size: 128
  #     verbose_evals: true
  #     metrics:
  #       - "forward_pass_count"
  #       - "validation_loss"
  #       - "consensus_error"
  #       - "top1_accuracy"
  #       - "current_epoch"
  #     metrics_config:
  #       evaluate_frequency: 20
  #     optimizer_config:
  #       alg_name: "sonata"
  #       alpha: 1
  #       tau: 0.1
  #       use_prox: False
  #       outer_iterations: 2000
  #       primal_iterations: 2
  #       init_grads: True
  #       primal_optimizer: "adam"
  #       persistant_primal_opt: false
  #       primal_lr_start: 0.005
  #       primal_lr_finish: 0.0005
  #       lr_decay_type: "log"
  #       profile: false
  # problem2:
  #   problem_name: "dsgt"
  #   train_batch_size: 64
  #   val_batch_size: 128
  #   verbose_evals: true
  #   metrics:
  #     - "forward_pass_count"
  #     - "validation_loss"
  #     - "consensus_error"
  #     - "top1_accuracy"
  #     - "current_epoch"
  #   metrics_config:
  #     evaluate_frequency: 20
  #   optimizer_config:
  #     alg_name: "dsgt"
  #     outer_iterations: 2000
  #     alpha: 0.005
  #     init_grads: True
  #     profile: false
  # problem3:
  #   problem_name: "dsgd"
  #   train_batch_size: 64
  #   val_batch_size: 128
  #   verbose_evals: true
  #   metrics:
  #     - "forward_pass_count"
  #     - "validation_loss"
  #     - "consensus_error"
  #     - "top1_accuracy"
  #     - "current_epoch"
  #   metrics_config:
  #     evaluate_frequency: 20
  #   optimizer_config:
  #     alg_name: "dsgd"
  #     outer_iterations: 2000
  #     alpha0: 0.005
  #     mu: 0.001
  #     profile: false